{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio Aprendizaje Automático para Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este laboratorio, exploraremos cómo utilizar dos algoritmos de aprendizaje supervisado, Random Forest y Support Vector Machines (SVM), para la clasificación de imágenes. Utilizaremos un conjunto de datos proporcionado por kaggle y realizaremos una serie de pasos para preprocesar los datos, entrenar los modelos y evaluar su rendimiento. Además, recordaremos algunos de los modelos de extracción manual de características vistos durante el primer módulo del curso y su impacto al momento de entrenar un modelo de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparación del entorno\n",
    "\n",
    "Primero, importamos las bibliotecas necesarias.\n",
    "\n",
    "#### ¿Qué es sklearn?\n",
    "**sklearn** es una librería de Python que proporciona herramientas simples y eficientes para el análisis de datos y el modelado predictivo. Es ampliamente utilizada en el ámbito del aprendizaje automático (Machine Learning) debido a su simplicidad y facilidad de uso.\n",
    "\n",
    "#### Utilidad en Modelos de Aprendizaje Automático\n",
    "\n",
    "- **Modelos Incluidos:** sklearn incluye una variedad de modelos de aprendizaje automático, como regresión, clasificación, clustering y reducción de dimensionalidad.\n",
    "- **Pipeline Completo:** Facilita todo el pipeline del aprendizaje automático desde el preprocesamiento de datos hasta la evaluación del modelo.\n",
    "\n",
    "#### Funcionamiento de los Modelos\n",
    "\n",
    "- **Entrenamiento del Modelo:** La función `.fit()` se utiliza para entrenar un modelo en un conjunto de datos.\n",
    "- **Predicción:** La función `.predict()` se utiliza para realizar predicciones sobre nuevos datos una vez que el modelo ha sido entrenado.\n",
    "\n",
    "#### Herramientas Importantes\n",
    "\n",
    "1. **Modelos de Machine Learning:**\n",
    "   - `RandomForestClassifier`, `SVC`, `LinearRegression`, entre otros.\n",
    "2. **Preprocesamiento de Datos:**\n",
    "   - `StandardScaler`, `MinMaxScaler`, `LabelEncoder`.\n",
    "3. **Evaluación de Modelos:**\n",
    "   - Métricas como `accuracy_score`, `classification_report`, `confusion_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Se importaron todos los paquetes necesarios para este laboratorio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cargar dataset\n",
    "El dataset que usaremos en este laboratorio fue obtenido de [kaggle](https://www.kaggle.com/datasets/niteshfre/chessman-image-dataset) y corresponde a un conjunto de imágenes de las seis fichas encontradas en el ajedrez. Te invitamos a explorar el dataset y destacar la variabilidad de los colores, la iluminación y demás elementos de las imágenes. Observando manualmente algunos ejemplares del dataset encontrarás también que para una misma clase, dos imágenes cuentan con distintos aspectos y fondos, lo cual incrementa la complejidad para nuestros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip chessman-image-dataset.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el directorio base del dataset\n",
    "base_dir = 'Chessman-image-dataset/Chess/'\n",
    "\n",
    "# Inicializar listas para imágenes y etiquetas\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Etiquetas de las clases\n",
    "classes = os.listdir(base_dir)\n",
    "sample_images = {}\n",
    "\n",
    "print(f\"Cargando dataset {base_dir}\")\n",
    "# Cargar imágenes y etiquetas\n",
    "for label in classes:\n",
    "    class_dir = os.path.join(base_dir, label)\n",
    "    for img_path in tqdm(glob.glob(os.path.join(class_dir, '*'))):\n",
    "        try:\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = img.resize((128, 128))  # Redimensionar las imágenes si es necesario\n",
    "            img = np.array(img)\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "            if label not in sample_images.keys():\n",
    "                sample_images[label] = img\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "\n",
    "# Convertir a numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "# Crea un arreglo con los indices de tomas las imágenes para más adelante hacer la división de los datos sobre estos valores.\n",
    "indices = np.arange(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora dividimos los datos en el conjunto de entrenamiento y de evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en conjuntos de entrenamiento, validación y prueba\n",
    "X_train_indices, X_test_indices = train_test_split(indices, test_size=0.2, stratify=labels, random_state=42)\n",
    "X_train = images[X_train_indices]\n",
    "y_train = labels[X_train_indices]\n",
    "\n",
    "X_test = images[X_test_indices]\n",
    "y_test = labels[X_test_indices]\n",
    "\n",
    "print(f'Tamaño del conjunto de entrenamiento: {len(X_train)}')\n",
    "print(f'Tamaño del conjunto de prueba: {len(X_test)}')\n",
    "\n",
    "# Verifica las dimensiones\n",
    "print(f'Dimensiones de las imágenes: {X_train[0].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Visualización del dataset:\")\n",
    "# Mostramos algunas imágenes del dataset\n",
    "fig, axes = plt.subplots(2, 3)\n",
    "for ax, cls in zip(axes.flatten(), classes):\n",
    "    random_img = sample_images[cls]\n",
    "    ax.imshow(random_img)\n",
    "    ax.set_title(cls)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento del modelo Random Forest\n",
    "\n",
    "A continuación, entrenaremos un modelo de Random Forest utilizando los datos de entrenamiento. Sugerimos revisar la documentación en [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier) para entender a mayor profundidad su funcionamiento y los parámetros con los que puedes experimentar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda presenta algunos de los parámetros de Random Forest estudiados en el curso. **Te invitamos a modificar estos y otros parámetros del modelo de Random Forest para estudiar su efecto en el rendimiento de la clasificación.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros para modelo Random Forest\n",
    "n_estimators = 10000 \n",
    "min_samples_split = 2\n",
    "bootstrap = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto el modelo de Random Forest, como el de SVM de sklearn requieren entradas de una dimensión. Por esto aplanaremos las imágenes para representar los datos con los vectores de sus intensidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar las entradas para Random Forest\n",
    "print(f\"Tamaño inicial del arreglo de train: {X_train.shape}\")\n",
    "## Aplanar las imágenes para ingresar vectores a los modelos de clasificación\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "print(f\"Tamaño del arreglo de train tras aplanar las imágenes: {X_train_flat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar y entrenar Random Forest\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=n_estimators, \n",
    "    min_samples_split=min_samples_split, \n",
    "    bootstrap=bootstrap,\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "rf_clf.fit(X_train_flat, y_train)\n",
    "# Evaluar el modelo\n",
    "y_pred_rf = rf_clf.predict(X_test_flat)\n",
    "print(\"Random Forest - Conjunto de evaluación\")\n",
    "print(classification_report(y_test, y_pred_rf, target_names=classes))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando resultados aleatorios de predicciones de Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(len(X_test), 4, replace=False)\n",
    "\n",
    "# Crear un subplot 2x3 para mostrar las imágenes\n",
    "fig, axes = plt.subplots(1, 4)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    idx = indices[i]\n",
    "    img = X_test[idx].reshape(128, 128, 3)\n",
    "    true_label = y_test[idx]\n",
    "    pred_label = y_pred_rf[idx]\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"True: {true_label}\\nPred: {pred_label}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Entrenamiento del modelo SVM para clasificación\n",
    "A continuación, entrenaremos un modelo de Support Vector Machines (SVM) utilizando los datos de entrenamiento. Sugerimos revisar la documentación en [sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC) para entender a mayor profundidad su funcionamiento y los parámetros con los que puedes experimentar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda presenta algunos de los parámetros de SVM estudiados en el curso. **Te invitamos a modificar estos y otros parámetros del modelo de SVM para estudiar su efecto en el rendimiento de la clasificación.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros para modelo Support Vector Machines\n",
    "kernel_type = 'linear' # {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}\n",
    "regularization_C = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar SVM\n",
    "svm_clf = SVC(kernel=kernel_type, random_state=42, C=regularization_C)\n",
    "svm_clf.fit(X_train_flat, y_train)\n",
    "y_pred_svm = svm_clf.predict(X_test_flat)\n",
    "print(\"SVM - Test\")\n",
    "print(classification_report(y_test, y_pred_svm, target_names=classes))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando resultados aleatorios de predicciones de SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(len(X_test), 4, replace=False)\n",
    "\n",
    "# Crear un subplot 2x3 para mostrar las imágenes\n",
    "fig, axes = plt.subplots(1, 4)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    idx = indices[i]\n",
    "    img = X_test[idx].reshape(128, 128, 3)\n",
    "    true_label = y_test[idx]\n",
    "    pred_label = y_pred_svm[idx]\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f\"True: {true_label}\\nPred: {pred_label}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo individual: explorando nuevas representaciones de los datos\n",
    "En la primera exploración de los clasificadores Random Forest y SVM, estos modelos buscaron categorizar las imágenes a partir de sus matrices de intensidades aplanadas. Ahora, explora clasificar las imágenes aplicando un preprocesamiento de los datos para obtener otros tipos de representaciones mediante la extracción manual de características.\n",
    "\n",
    "A continuación te presentamos un ejemplo de cómo se extraen los histogramas HOG y su visualización. Este procedimiento te puede guiar en la extracción de HOG como descriptor para el entrenamiento de un clasificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "from skimage import color\n",
    "\n",
    "print(\"Visualización de características:\")\n",
    "# Mostramos algunas imágenes del dataset\n",
    "fig, ax = plt.subplots(4, 2, figsize=(10, 7))\n",
    "for i in range(len(classes[2:])):\n",
    "    img = sample_images[classes[i]]\n",
    "    gray_img = color.rgb2gray(img)\n",
    "    \n",
    "    # HOG\n",
    "    # Revisa la documentación de la función para entender la utilidad de cada parámetro y cómo obtener los vectores en lugar de la visualización de HOG\n",
    "    ft_vec, hog_feature = hog(gray_img, pixels_per_cell=(8, 8),\n",
    "                      cells_per_block=(2, 2), feature_vector=True, visualize=True)\n",
    "    \n",
    "    ax[i, 0].imshow(img)\n",
    "    ax[i, 0].axis('off')\n",
    "\n",
    "    ax[i, 1].imshow(hog_feature)\n",
    "    ax[i, 1].axis('off')\n",
    "\n",
    "    # Agregar títulos a las columnas\n",
    "    if i == 0:\n",
    "        ax[i, 0].set_title(\"Imagen Original\")\n",
    "        ax[i, 1].set_title(\"Características HOG\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de características: histogramas de color y HOG\n",
    "Usa la función `hog()` de skimage.feature y la función `color()` de skimage para extraer los vectores de características de las imágenes. Recuerda que para obtener los histogramas HOG las imágenes deben presentarse en **escala de grises**.\n",
    "Para el caso de la representación por color te recomendamos **extraer el histograma de cada canal de color y concatenar los histogramas de los tres canales de las imágenes originales**. De este modo, la extracción de características resultará en arreglos de una sola dimensión que pueden ser procesados por los modelos de RF y de SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: recorre el arreglo \"images\" para obtener los vectores que describirán sus características HOG y de color. Para obtener la representación de HOG sigue el algoritmo presentado en el ejemplo anterior y asegúrate de que el argumento visualize sea False, ya que requieres los histogramas, pero no visualizarlos.\n",
    "\n",
    "# Guarda los vectores individuales en las listas \"hog_features\" y \"color_features\":\n",
    "# Extracción de características HOG e intensidades de color\n",
    "hog_features = []\n",
    "color_features = []\n",
    "\n",
    "# Recorre cada una de las imágenes en el dataset completo para obtener su respectivo vector de características de HOG y de histogramas de color concatenados.\n",
    "for img in images:\n",
    "    # Completa el código para obtener y guardar el vector de HOG y el de histogramas de color concatenados en las listas adecuadas:\n",
    "    # Convertir a escala de grises\n",
    "    gray_img = color.rgb2gray(img)\n",
    "    \n",
    "    # Extraer características HOG y almacenarlas en la lista de \"hog_features\"\n",
    "    ### BEGIN SOLUTION\n",
    "    # TODO: ¡Atención! Acá debes obtener las características HOG como en el ejemplo de la celda anterior.\n",
    "    hog_feature = None # Reemplaza \"None\" por el código asociado a la función hog() de skimage.feature.\n",
    "    ### END SOLUTION\n",
    "    hog_features.append(hog_feature)\n",
    "    \n",
    "    # Extraer un histogramas de color por cada canal, concatenarlos como un único vector por imagen en \"hist_feature\" y almacenarlo en la lista de \"color_features\".\n",
    "    hist_feature = []\n",
    "    for channel in range(3):\n",
    "        hist, _ = np.histogram(img[:, :, channel], bins=256, range=(0, 256))\n",
    "        hist_feature.extend(hist)\n",
    "    color_features.append(hist_feature)\n",
    "    \n",
    "    # ¡Atención!\n",
    "    # Asegúrate de que cada elemento que agregues a las listas hog_features y a color_features respectivamente sean arreglos de una sola dimensión,\n",
    "    # de modo que al final de esta celda obtengas para cada uno de ellos un arreglo de arreglos unidimensionales.\n",
    "    hog_features.append(hog_feature) \n",
    "    color_features.append(hist_feature)\n",
    "\n",
    "# Convertir a numpy arrays\n",
    "hog_features = np.array(hog_features)\n",
    "color_features = np.array(color_features)\n",
    "\n",
    "print(\"Extracción de características finalizada. Los vectores de características están almacenados en 'hog_features' y 'color_features', respectivamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisando los resultados de tu ejecución...\n",
    "assert len(hog_features[0].shape) == 1, \"Error en la obtención de los vectores de características de HOG. Los vectores no cumplen con las dimensiones establecidas.\"\n",
    "\n",
    "assert len(color_features[0].shape) == 1, \"Error en la obtención de los vectores de características de color. Los vectores no cumplen con las dimensiones establecidas.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y evaluación de RF con HOG e histogramas concatenados de colores\n",
    "\n",
    "Antes de explorar el uso de los clasificadores con nuestros nuevos descriptores dividiremos nuestros vectores de características en los sets de entrenamiento y evaluación respetando la división de datos seguida en los anteriores modelos.\n",
    "\n",
    "**¡Atención!** Recuerda usar el parámetro random_state=42 al declarar cada modelo que se requiera en las siguientes fases del laboratorio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_hog_fts = hog_features[X_train_indices]\n",
    "X_test_hog_fts = hog_features[X_test_indices]\n",
    "\n",
    "X_train_color_fts = color_features[X_train_indices]\n",
    "X_test_color_fts = color_features[X_test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectores de HOG\n",
    "\n",
    "Completa el código faltante en la siguiente celda para construir el modelo en la variable `rf_clf_HOG` y entrenarlo con las **características HOG de las imágenes**. Además, obtén las predicciones sobre el set de evaluación en la variable `y_pred_rf_HOG`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar y entrenar Random Forest con características HOG\n",
    "# TODO: declara el modelo Random Forest en la variable \"rf_clf_HOG\" y entrenalo con los vectores de características del set de entrenamiento. Recuerda que debes tomar como ejemplo el código con el que declaramos y entrenamos un RF al inicio del laboratorio.\n",
    "### BEGIN SOLUTION\n",
    "rf_clf_HOG = None # Reemplaza \"None\" por el código asociado a la función RandomForestClassifier de sklearn.ensemble.\n",
    "### END SOLUTION\n",
    "\n",
    "rf_clf_HOG.fit(X_train_hog_fts, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "# TODO: obten las predicciones del modelo entrenado \"rf_clf_HOG\" para el set de evaluación en la variable \"y_pred_rf_HOG\". \n",
    "### BEGIN SOLUTION\n",
    "y_pred_rf_HOG = None # Reemplaza \"None\" por el código asociado a la obtención de predicciones del modelo previamente entrenado.\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisando los resultados de tu ejecución...\n",
    "assert isinstance(rf_clf_HOG, RandomForestClassifier), \"El modelo rf_clf_HOG no ha sido correctamente declarado como una instancia de RandomForestClassifier.\"\n",
    "\n",
    "assert len(y_pred_rf_HOG) == len(X_test_hog_fts), f\"El número de predicciones ({len(y_pred_rf_HOG)}) no coincide con el número de muestras en el conjunto de prueba ({len(X_test_hog_fts)}).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas\n",
    "print(\"Random Forest, HOG features - Conjunto de evaluación\")\n",
    "print(classification_report(y_test, y_pred_rf_HOG, target_names=classes))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf_HOG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectores de histogramas concatenados\n",
    "\n",
    "Completa el código faltante en la siguiente celda para construir el modelo en la variable `rf_clf_color_hist` y entrenarlo con las **los vectores de histogramas concatenados de las imágenes**. Además, obtén las predicciones sobre el set de evaluación en la variable `y_pred_rf_color_hist`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar y entrenar Random Forest con características de color.\n",
    "# TODO: declara el modelo Random Forest en la variable \"rf_clf_color_hist\" y entrenalo con los vectores de características del set de entrenamiento. Recuerda que debes tomar como ejemplo el código con el que declaramos y entrenamos un RF al inicio del laboratorio.\n",
    "### BEGIN SOLUTION\n",
    "rf_clf_color_hist = None # Reemplaza \"None\" por el código asociado a la función RandomForestClassifier de sklearn.ensemble.\n",
    "### END SOLUTION\n",
    "\n",
    "rf_clf_color_hist.fit(X_train_color_fts, y_train)\n",
    "\n",
    "\n",
    "# Evaluar el modelo\n",
    "# TODO: obten las predicciones del modelo entrenado \"rf_clf_color_hist\" para el set de evaluación en la variable \"y_pred_rf_color_hist\".\n",
    "### BEGIN SOLUTION\n",
    "y_pred_rf_color_hist = None # Reemplaza \"None\" por el código asociado a la obtención de predicciones del modelo previamente entrenado.\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisando los resultados de tu ejecución...\n",
    "assert isinstance(rf_clf_color_hist, RandomForestClassifier), \"El modelo rf_clf_color_hist no ha sido correctamente declarado como una instancia de RandomForestClassifier.\"\n",
    "\n",
    "assert len(y_pred_rf_color_hist) == len(X_test_color_fts), f\"El número de predicciones ({len(y_pred_rf_color_hist)}) no coincide con el número de muestras en el conjunto de prueba ({len(X_test_color_fts)}).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular métricas\n",
    "print(\"Random Forest, concatenated color histograms features - Conjunto de evaluación\")\n",
    "print(classification_report(y_test, y_pred_rf_color_hist, target_names=classes))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf_color_hist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y evaluación de SVM con HOG e histogramas concatenados de colores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las siguientes celdas realiza el código para declarar, entrenar y evaluar el modelo de SVM usando (A) los vectores con la representación HOG y (B) los histogramas concatenados de las imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(A) Representación de los datos: HOG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar y entrenar SVM con características de HOG.\n",
    "# TODO: declara el modelo SVM en la variable \"svm_clf_HOG\" y entrenalo con los vectores de características del set de entrenamiento. Recuerda que debes tomar como ejemplo el código con el que declaramos y entrenamos un modelo SVM al inicio del laboratorio.\n",
    "# Entrenar SVM\n",
    "### BEGIN SOLUTION\n",
    "svm_clf_HOG = None # Reemplaza \"None\" por el código asociado a la función SVC de sklearn.svm.\n",
    "### END SOLUTION\n",
    "\n",
    "svm_clf_HOG.fit(X_train_hog_fts, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "# TODO: obten las predicciones del modelo entrenado \"svm_clf_HOG\" para el set de evaluación en la variable \"y_pred_svm_HOG\"\n",
    "### BEGIN SOLUTION\n",
    "y_pred_svm_HOG = None # Reemplaza \"None\" por el código asociado a la obtención de predicciones del modelo previamente entrenado.\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Revisando los resultados de tu ejecución...\n",
    "assert isinstance(svm_clf_HOG, SVC), \"El modelo svm_clf_HOG no ha sido correctamente declarado como una instancia de Support Vector Machines.\"\n",
    "\n",
    "assert len(y_pred_svm_HOG) == len(X_test_hog_fts), f\"El número de predicciones ({len(y_pred_svm_HOG)}) no coincide con el número de muestras en el conjunto de prueba ({len(X_test_hog_fts)}).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalúa el desempeño sobre el set de test.\n",
    "print(\"SVM, HOG features - Test\")\n",
    "print(classification_report(y_test, y_pred_svm_HOG, target_names=classes))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm_HOG))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(B) Representación de los datos: Histogramas de colores concatenados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar y entrenar SVM con características de HOG.\n",
    "# TODO: declara el modelo SVM en la variable \"svm_clf_color_hist\" y entrenalo con los vectores de características del set de entrenamiento. Recuerda que debes tomar como ejemplo el código con el que declaramos y entrenamos un modelo SVM al inicio del laboratorio.\n",
    "# Entrenar SVM\n",
    "### BEGIN SOLUTION\n",
    "svm_clf_color_hist = None # Reemplaza \"None\" por el código asociado a la función SVC de sklearn.svm.\n",
    "### END SOLUTION\n",
    "\n",
    "svm_clf_color_hist.fit(X_train_color_fts, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "# TODO: obten las predicciones del modelo entrenado \"svm_clf_color_hist\" para el set de evaluación en la variable \"y_pred_svm_color_hist\"\n",
    "### BEGIN SOLUTION\n",
    "y_pred_svm_color_hist = None # Reemplaza \"None\" por el código asociado a la obtención de predicciones del modelo previamente entrenado.\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisando los resultados de tu ejecución...\n",
    "assert isinstance(svm_clf_color_hist, SVC), \"El modelo svm_clf_color_hist no ha sido correctamente declarado como una instancia de Support Vector Machines.\"\n",
    "\n",
    "assert len(y_pred_svm_color_hist) == len(X_test_color_fts), f\"El número de predicciones ({len(y_pred_svm_color_hist)}) no coincide con el número de muestras en el conjunto de prueba ({len(X_test_color_fts)}).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalúa el desempeño sobre el set de test.\n",
    "print(\"SVM, concatenated color histograms features - Test\")\n",
    "print(classification_report(y_test, y_pred_svm_color_hist, target_names=classes))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm_color_hist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métricas finales:\n",
    "En el siguiente diccionario reporta los valores de accuracy obtenidos a lo largo de este laboratorio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingresa en la llave correspondiente el resultado de accuracy (en set de evaluación) para cada modelo y cada tipo de representación:\n",
    "# Estos resultados deben registrarse con datos de tipo numerico.\n",
    "final_metrics = {\n",
    "    'RF_flat_imgs': None,\n",
    "    'RF_HOG_fts': None,\n",
    "    'RF_histog_fts': None,\n",
    "\n",
    "    'SVM_flat_imgs': None,\n",
    "    'SVM_HOG_fts': None,\n",
    "    'SVM_histog_fts': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisando los resultados de tu ejecución...\n",
    "assert (final_metrics['RF_HOG_fts'] > final_metrics['RF_flat_imgs']) and (final_metrics['RF_histog_fts'] > final_metrics['RF_flat_imgs']), \"Los resultados de accuracy obtenidos no concuerdan con los esperados. Revisa detenidamente el entrenamiento y las predicciones de los modelos entrenados con HOG y con los histogramas concatenados.\"\n",
    "\n",
    "assert (final_metrics['SVM_HOG_fts'] > final_metrics['SVM_flat_imgs']) and (final_metrics['SVM_histog_fts'] > final_metrics['SVM_flat_imgs']), \"Los resultados de accuracy obtenidos no concuerdan con los esperados. Revisa detenidamente el entrenamiento y las predicciones de los modelos entrenados con HOG y con los histogramas concatenados.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Al finalizar:\n",
    "Compara el rendimiento de estos modelos entrenados en las nuevas representaciones con aquellos entrenados en las matrices aplanadas. ¿Existe algún beneficio en representar las imágenes con características distintas a sus matrices aplanadas? ¿Cuál de los modelos tiene mejor desempeño al representar los datos con las matrices aplanadas? ¿Estos resultados se mantienen al entrenar sobre las nuevas representaciones? Comparte tus observaciones en la sesión sincrónica del curso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MaIA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
